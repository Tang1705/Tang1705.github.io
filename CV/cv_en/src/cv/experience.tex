%-------------------------------------------------------------------------------
%	SECTION TITLE
%-------------------------------------------------------------------------------
\cvsection{EXPERIENCES}


%-------------------------------------------------------------------------------
%	CONTENT
%-------------------------------------------------------------------------------
\begin{cventries}

    %---------------------------------------------------------
    \ecventry
    {Principal Investigator} % Job title
    {Research on Joint Depth Map Super-Resolution \newline and Monocular Depth Estimation Algorithm \href{http://jw.beijing.gov.cn/xxgk/zxxxgk/202111/t20211119_2540974.html}{{\color{awesome}\faLink}}
    } % Organization
    {The Institute of Information Science, Beijing Jiaotong University\newline\vspace{-0.5mm}\hspace{-10mm} Beijing Key Laboratory of Advanced Information Science and Network Technology} % Location
    {Dec. 2020 - Jun. 2021} % Date(s)
    {
        \begin{cvitems} % Description(s) of tasks/responsibilities
            \item {Existing color-guided depth map super-resolution methods usually necessitate an extra branch to extract high-frequency detail information from RGB image to guide the low-resolution depth map reconstruction. However, because there are still some differences between the two modalities, direct information transmission in the feature dimension or edge map dimension cannot achieve satisfactory result, and may even trigger texture copying in areas where the structures of the RGB-D pair are inconsistent. Inspired by the multi-task learning, we propose a joint learning network of depth map super-resolution (DSR) and monocular depth estimation (MDE) without introducing additional supervision labels. }
            \item {\textbf{The project is the recipient of the Excellent Undergraduate Graduation Design (Thesis) of Beijing Ordinary Colleges and Universities}. A paper is accepted by ACM International Conference on Multimedia. The invention publication has passed the preliminary examination (\textbf{A Method of Depth Map Super-Resolution joint Monocular Depth Estimation}, application number: 202110803976.2).\href{https://github.com/rmcong/BridgeNet_ACM-MM-2021}{{\color{awesome}\faGithub}}}
            \item {Implement based on Python, PyTorch, MindSpore}
        \end{cvitems}
    }

    %---------------------------------------------------------
    \ecventry
    {Principal Investigator} % Job title
    {3D Reconstruction of High-Speed Rail-Wheel \newline Based on Coded Structured Light \href{http://gjcxcy.bjtu.edu.cn/NewLXItemListForStudentDetail.aspx?ItemNo=594113&year=2020&type=student&IsLXItem=1}{{\color{awesome}\faLink}}
    } % Organization
    {School of Computer and Information Technology, Beijing Jiaotong University\newline\vspace{-0.5mm}\hspace{-10mm} Rail Transit Intelligent Inspection and Monitoring Institute} % Location
    {Apr. 2019 - Jul. 2020} % Date(s)
    {
        \begin{cvitems} % Description(s) of tasks/responsibilities
            \item {The wheel-rail attitude of high-speed railway reflects the complex dynamic interaction and restraint relationship
            between wheels and rails. Obtaining high-precision high-speed railway wheel-rail attitude is of great significance for
            ensuring the safe operation of high-speed railways. This project is based on machine vision theory and methods, and focuses
            on the 3D reconstruction method of high-speed rail wheel-rail attitude based on coded structured light.}
            \item {\textbf{The project is supported by National Training Program of Innovation and Entrepreneurship for Undergraduates}.
            We adopt the method of coded structured light based on space codification, projecting a single pattern on the surface of the
            wheel and track, improving the accuracy of feature point extraction and recognition. And we combine De Bruijn analysis with
            wavelet transform analysis, increasing the density of point cloud and realizing the dense reconstruction by a single shot.
            The development of 3D reconstruction software based on coded structured light, offering a platform for the 3D reconstruction
            based on active vision, visualization and editing of point cloud data, is selected as one of the top 99 C++ 3D reconstruction
            open source projects on Github (Awesome Open Source). \href{https://github.com/Tang1705/Reconstruction}{{\color{awesome}\faGithub}}}
            \item {Development based on C++, OpenCV, PCL, QT}
        \end{cvitems}
    }
    %---------------------------------------------------------
\end{cventries}
